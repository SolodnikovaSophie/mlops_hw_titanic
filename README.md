# MLOps-пайплайн с контролем data drift и A/B-тестированием

## Описание проекта

В рамках проекта реализован end-to-end MLOps-пайплайн для задачи бинарной классификации
(датасет Titanic).

Цель проекта — продемонстрировать полный жизненный цикл модели машинного обучения
в production-среде: от мониторинга входных данных до безопасного внедрения новой версии модели.
Акцент сделан на автоматизации процессов обучения, тестирования и выката модели,
а не на максимизации качества конкретного алгоритма.

---

## Цель и задачи

Цель проекта — построить воспроизводимый и управляемый MLOps-пайплайн, включающий:

- контроль data drift между обучающими и текущими данными;
- условное переобучение модели при обнаружении drift;
- автоматизированное обучение с использованием AutoML;
- логирование экспериментов и версионирование моделей;
- A/B-тестирование моделей в production-среде;
- автоматическое принятие решения о переводе модели в Production.

---

## Архитектура решения

Общая логика пайплайна:

Данные -> Контроль data drift (PSI)  -> Условное переобучение модели  -> MLflow (эксперименты и Model Registry) -> A/B-тестирование через API  -> Автоматический перевод модели в Production  


---

## Основные компоненты

### Контроль data drift

Для контроля изменения распределений входных данных используется метрика
Population Stability Index (PSI).

- Сравниваются обучающие (train) и текущие (current) данные.
- PSI рассчитывается для признаков Age, Fare и Pclass.
- Вычисляется среднее значение PSI по всем признакам.
- При превышении заданного порога считается, что произошёл значимый data drift.

Контроль drift реализован в Airflow DAG `drift_retrain_dag`.

---

### Условное переобучение модели

Переобучение модели выполняется по событию, а не по расписанию.

Логика:
- если среднее значение PSI превышает порог, запускается переобучение;
- при отсутствии значимого drift переобучение пропускается.

Данный подход позволяет избежать ненужного обучения и снизить затраты вычислительных ресурсов.

---

### Обучение модели (AutoML)

Обучение модели реализовано с использованием библиотеки PyCaret и включает:

- автоматический подбор модели;
- кросс-валидацию;
- выбор лучшей модели по метрике recall;
- финализацию модели для использования в production.

Все этапы обучения логируются в MLflow:
- параметры preprocessing;
- метрики качества;
- артефакты модели.

---

### MLflow и Model Registry

MLflow используется для хранения экспериментов и управления жизненным циклом моделей.

- MLflow Runs содержат метрики, параметры и артефакты обучения.
- MLflow Model Registry используется для версионирования моделей и управления стадиями
  (Staging, Production).

Model Registry ссылается на соответствующие runs, в которых сохранены результаты обучения.

---

### A/B-тестирование моделей

A/B-тестирование реализовано через Flask API.

Используются две версии модели:
- A — текущая модель в стадии Production;
- B — новая модель в стадии Staging.

Разделение трафика выполняется:
- детерминированно по user_id;
- либо случайно по заданной доле трафика.

Каждый запрос логируется с указанием:
- варианта A или B;
- версии модели;
- входных признаков;
- предсказания и ground truth (если доступен).

---

### Оценка A/B-теста и перевод модели в Production

Оценка результатов A/B-теста выполняется в Airflow DAG `ab_evaluate_and_promote`.

Процесс включает:
- расчёт метрик accuracy, precision, recall и F1-score для моделей A и B;
- проверку статистической значимости различий по accuracy с использованием chi-square теста;
- принятие решения о переводе модели B в Production.

Модель переводится в Production только при выполнении двух условий:
- качество модели B выше качества модели A;
- различие статистически значимо.

---

## Используемые технологии

- Python
- Apache Airflow
- MLflow
- PyCaret
- Flask
- Docker
- scikit-learn
- pandas

---

## Состав сервисов и инфраструктура

Проект разворачивается в Docker и включает следующие сервисы:

### Flask API (`mlops-api`)
- инференс моделей;
- A/B-роутинг запросов;
- логирование событий инференса;
- управление конфигурацией A/B-тестирования.

### Apache Airflow
- контроль data drift;
- условное переобучение модели;
- запуск A/B-оценки;
- автоматический перевод модели в Production.

### MLflow
- Tracking Server для экспериментов;
- Model Registry для управления версиями моделей.

### PostgreSQL
Используется как база данных для хранения метаданных Airflow.

---

## Пользовательские интерфейсы

После запуска Docker Compose доступны следующие интерфейсы:

- Airflow UI: `http://localhost:8080`
- Flask API: `http://localhost:8000`
- Swagger UI: `http://localhost:8000/apidocs`
- MLflow UI: `http://localhost:5000`

---

## Структура проекта

Основные директории проекта:

- `app/` — Flask API и A/B-роутинг;
- `dags/` — DAG-и Airflow;
- `training/` — обучение, регистрация и оценка моделей;
- `data/` — обучающие и текущие датасеты;
- `logs/` — логи выполнения пайплайна.

---

## Переменные окружения

Ключевые переменные окружения:

- `MODEL_NAME` — имя модели в MLflow Model Registry;
- `MLFLOW_TRACKING_URI` — адрес MLflow Tracking Server;
- `TRAIN_PATH` — путь к обучающему датасету;
- `CURRENT_PATH` — путь к текущему датасету;
- `DRIFT_THRESHOLD` — порог для метрики PSI;
- `AB_SPLIT_B` — доля трафика для модели B;
- `AB_LOG_PATH` — путь к CSV-файлу логов A/B-тестирования.

---

## Запуск проекта

### Запуск инфраструктуры

```bash
docker compose up -d --build


